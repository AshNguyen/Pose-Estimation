{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Classification] Experimentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCb6SUJQxnP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys, random, os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/capstone_code\")\n",
        "sys.path.append(\"/content/drive/My Drive/capstone_code/p_file\")\n",
        "\n",
        "train = pd.read_csv(\"./training_set.csv\")\n",
        "test = pd.read_csv(\"./test_set.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHZ2ecrOOkDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(nframe=5, n_aug=0, skip_frame=1):\n",
        "    train = pd.read_csv(\"./training_set.csv\")\n",
        "    test = pd.read_csv(\"./test_set.csv\")\n",
        "    from preprocessing.serialization import serialize_data_clf, serialize_data_clf_val\n",
        "    from models.data_generator import data_generator_clf\n",
        "\n",
        "    train_input, train_label, encoder =  serialize_data_clf(nframe, train, n_aug=n_aug, skip_frame=skip_frame, save=True, save_path=\"./\")\n",
        "    val_input, val_label, encoder =  serialize_data_clf_val(encoder, nframe, test, n_aug=n_aug, skip_frame=skip_frame, save=True, save_path=\"./\")\n",
        "\n",
        "    train_generator = data_generator_clf(train_input, train_label, batch_size=64)\n",
        "    val_generator = data_generator_clf(val_input, val_label, batch_size=64, augmented=False)  \n",
        "    return train_generator, val_generator, encoder\n",
        "\n",
        "def train_model_org(save_path, nframe=5, n_aug=0, skip_frame=1, n_epoch=100, n_latent_layer = 3, latent_unit = 100, dropout_rate = 0.2, lr = 0.001, save_train_stats=True):\n",
        "      from models.classification import classification_model\n",
        "      model = classification_model(save_dir = save_path, nframe=nframe, n_latent_layer = n_latent_layer, latent_unit = latent_unit, dropout_rate = dropout_rate, lr = lr, early_stop=False)\n",
        "      train_generator, val_generator, encoder = load_data(nframe, n_aug, skip_frame)\n",
        "      print(\"Training model:\"+save_path)\n",
        "      history = model.training_generator(train_generator, val_generator, 500, 200, n_epoch=n_epoch)\n",
        "      if save_train_stats: \n",
        "          np.array(history.history['acc']).dump(save_path+\"_stats_tacc\")\n",
        "          np.array(history.history['val_acc']).dump(save_path+\"_stats_vacc\")\n",
        "          np.array(history.history['loss']).dump(save_path+\"_stats_tlosss\")\n",
        "          np.array(history.history['val_loss']).dump(save_path+\"_stats_vloss\")\n",
        "      return model, history, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LA4N18QfbLOD",
        "colab": {}
      },
      "source": [
        "nframes = [1, 5, 10]\n",
        "skip_frames = [1, 2, 4]\n",
        "\n",
        "for nframe in nframes:\n",
        "    for skip_frame in skip_frames: \n",
        "        save_path = \"clf_{}frame_{}skip_default\".format(nframe, skip_frame)\n",
        "        train_model_org(save_path, nframe=nframe, skip_frame=skip_frame, save_train_stats=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDPXWvcmOnsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_latent_layers = [3, 6, 9]\n",
        "latent_units = [100, 200, 300]\n",
        "\n",
        "\n",
        "for n_latent_layer in n_latent_layers:\n",
        "    for latent_unit in latent_units: \n",
        "        save_path = \"clf_5frame_2skip_{\b}layer_{}unit\".format(n_latent_layer, latent_unit)\n",
        "        train_model_org(save_path, nframe=5, skip_frame=2, n_latent_layer = n_latent_layer, latent_unit = latent_unit, save_train_stats=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtFYbN6PQbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_rates = [0.1, 0.2, 0.25]\n",
        "lrs = [0.001, 0.05, 0.01]\n",
        "\n",
        "for dropout_rate in dropout_rates:\n",
        "    for lr in lrs: \n",
        "        save_path = \"clf_5frame_2skip_{}dr_{}lr\".format(dropout_rate, lr)\n",
        "        train_model_org(save_path, nframe=5, skip_frame=2, dropout_rate = dropout_rate, lr = lr, save_train_stats=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}