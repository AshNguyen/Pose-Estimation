{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenPose - Pytorch Implementation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0TlTTYqvvdR",
        "colab_type": "code",
        "outputId": "63d5b905-f30c-4f50-ca21-9b9d4b8b9152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os \n",
        "\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfHRkOIvOXHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adapted from https://github.com/Hzzone/pytorch-openpose\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "def constructing_block(block, not_relu_layer):\n",
        "    layers = []\n",
        "    for layer_name, v in block.items():\n",
        "        #Pooling layer\n",
        "        if 'pool' in layer_name:\n",
        "            layer = nn.MaxPool2d(kernel_size=v[0], stride=v[1], padding=v[2])\n",
        "            layers.append((layer_name, layer))\n",
        "        \n",
        "        #Convolution layer\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n",
        "                               kernel_size=v[2], stride=v[3],\n",
        "                               padding=v[4])\n",
        "            layers.append((layer_name, conv2d))\n",
        "            \n",
        "            #Add RELU\n",
        "            if layer_name not in not_relu_layer:\n",
        "                layers.append(('relu_'+layer_name, nn.ReLU(inplace=True)))\n",
        "\n",
        "    return nn.Sequential(OrderedDict(layers))\n",
        "\n",
        "class Pose_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Pose_Net, self).__init__()\n",
        "\n",
        "        # Names of layers with no RELU activation\n",
        "        no_relu_layers = ['conv5_5_CPM_L1', 'conv5_5_CPM_L2', 'Mconv7_stage2_L1',\\\n",
        "                          'Mconv7_stage2_L2', 'Mconv7_stage3_L1', 'Mconv7_stage3_L2',\\\n",
        "                          'Mconv7_stage4_L1', 'Mconv7_stage4_L2', 'Mconv7_stage5_L1',\\\n",
        "                          'Mconv7_stage5_L2', 'Mconv7_stage6_L1', 'Mconv7_stage6_L1']\n",
        "        blocks = {}\n",
        "\n",
        "\n",
        "        #First stage: detecting keypoints\n",
        "        \n",
        "        self.block0 = constructing_block(OrderedDict({'conv1_1': [3, 64, 3, 1, 1],                      #[input size, output size, kernel size, stride, padding]\n",
        "                                                      'conv1_2': [64, 64, 3, 1, 1],\n",
        "                                                      'pool1_kp': [2, 2, 0],                            #[kernel size, stride, padding]\n",
        "                                                      'conv2_1': [64, 128, 3, 1, 1],\n",
        "                                                      'conv2_2': [128, 128, 3, 1, 1],\n",
        "                                                      'pool2_kp': [2, 2, 0],\n",
        "                                                      'conv3_1': [128, 256, 3, 1, 1],\n",
        "                                                      'conv3_2': [256, 256, 3, 1, 1],\n",
        "                                                      'conv3_3': [256, 256, 3, 1, 1],\n",
        "                                                      'conv3_4': [256, 256, 3, 1, 1],\n",
        "                                                      'pool3_kp': [2, 2, 0],\n",
        "                                                      'conv4_1': [256, 512, 3, 1, 1],\n",
        "                                                      'conv4_2': [512, 512, 3, 1, 1],\n",
        "                                                      'conv4_3_CPM': [512, 256, 3, 1, 1],\n",
        "                                                      'conv4_4_CPM': [256, 128, 3, 1, 1]}), no_relu_layers)\n",
        "        \n",
        "        self.block1_1 = constructing_block(OrderedDict({'conv5_1_CPM_L1': [128, 128, 3, 1, 1],\n",
        "                                                        'conv5_2_CPM_L1': [128, 128, 3, 1, 1],\n",
        "                                                        'conv5_3_CPM_L1': [128, 128, 3, 1, 1],\n",
        "                                                        'conv5_4_CPM_L1': [128, 512, 1, 1, 0],\n",
        "                                                        'conv5_5_CPM_L1': [512, 38, 1, 1, 0]}), no_relu_layers)\n",
        "\n",
        "        self.block1_2 = constructing_block(OrderedDict({'conv5_1_CPM_L2': [128, 128, 3, 1, 1],\n",
        "                                                        'conv5_2_CPM_L2': [128, 128, 3, 1, 1],\n",
        "                                                        'conv5_3_CPM_L2': [128, 128, 3, 1, 1],\n",
        "                                                        'conv5_4_CPM_L2': [128, 512, 1, 1, 0],\n",
        "                                                        'conv5_5_CPM_L2': [512, 19, 1, 1, 0]}), no_relu_layers)\n",
        "\n",
        "        # Second stage: inferring individuals\n",
        "        for i in range(2, 7):\n",
        "            blocks['block%d_1' % i] = OrderedDict({\n",
        "                                'Mconv1_stage%d_L1' % i: [185, 128, 7, 1, 3],\n",
        "                                'Mconv2_stage%d_L1' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv3_stage%d_L1' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv4_stage%d_L1' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv5_stage%d_L1' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv6_stage%d_L1' % i: [128, 128, 1, 1, 0],\n",
        "                                'Mconv7_stage%d_L1' % i: [128, 38, 1, 1, 0]})\n",
        "\n",
        "            blocks['block%d_2' % i] = OrderedDict({\n",
        "                                'Mconv1_stage%d_L2' % i: [185, 128, 7, 1, 3],\n",
        "                                'Mconv2_stage%d_L2' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv3_stage%d_L2' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv4_stage%d_L2' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv5_stage%d_L2' % i: [128, 128, 7, 1, 3],\n",
        "                                'Mconv6_stage%d_L2' % i: [128, 128, 1, 1, 0],\n",
        "                                'Mconv7_stage%d_L2' % i: [128, 19, 1, 1, 0]})\n",
        "\n",
        "        for k in blocks.keys():\n",
        "            blocks[k] =constructing_block(blocks[k], no_relu_layers)\n",
        "\n",
        "        self.block2_1 = blocks['block2_1']\n",
        "        self.block3_1 = blocks['block3_1']\n",
        "        self.block4_1 = blocks['block4_1']\n",
        "        self.block5_1 = blocks['block5_1']\n",
        "        self.block6_1 = blocks['block6_1']\n",
        "\n",
        "        self.block2_2 = blocks['block2_2']\n",
        "        self.block3_2 = blocks['block3_2']\n",
        "        self.block4_2 = blocks['block4_2']\n",
        "        self.block5_2 = blocks['block5_2']\n",
        "        self.block6_2 = blocks['block6_2']\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out1 = self.block0(x)\n",
        "\n",
        "        out1_1 = self.block1_1(out1)\n",
        "        out1_2 = self.block1_2(out1)\n",
        "        out2 = torch.cat([out1_1, out1_2, out1], 1)\n",
        "\n",
        "        out2_1 = self.block2_1(out2)\n",
        "        out2_2 = self.block2_2(out2)\n",
        "        out3 = torch.cat([out2_1, out2_2, out1], 1)\n",
        "\n",
        "        out3_1 = self.block3_1(out3)\n",
        "        out3_2 = self.block3_2(out3)\n",
        "        out4 = torch.cat([out3_1, out3_2, out1], 1)\n",
        "\n",
        "        out4_1 = self.block4_1(out4)\n",
        "        out4_2 = self.block4_2(out4)\n",
        "        out5 = torch.cat([out4_1, out4_2, out1], 1)\n",
        "\n",
        "        out5_1 = self.block5_1(out5)\n",
        "        out5_2 = self.block5_2(out5)\n",
        "        out6 = torch.cat([out5_1, out5_2, out1], 1)\n",
        "\n",
        "        out6_1 = self.block6_1(out6)\n",
        "        out6_2 = self.block6_2(out6)\n",
        "\n",
        "        return out6_1, out6_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-jeTc-8chOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Packages\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.cluster import KMeans\n",
        "import skimage.segmentation as ski\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as opt\n",
        "import matplotlib.pyplot as plt\n",
        "# from tensorboardX import SummaryWriter\n",
        "import subprocess\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOm_M2cUchRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set image size\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "\n",
        "'''\n",
        "CREATE THE DATA\n",
        "'''\n",
        "\n",
        "class NumPyDataset(Dataset):\n",
        "    \"\"\" Creates a Pytorch Dataset out of Numpy arrays. \"\"\"\n",
        "    def __init__(self, X, y, transform_img=None, transform_mask=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform_img = transform_img\n",
        "        self.transform_mask = transform_mask\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Turn arrays into images\n",
        "        X_sample = Image.fromarray((self.X[index] * 255).astype(np.uint8))\n",
        "        y_sample = Image.fromarray((self.y[index]).astype(np.uint8))\n",
        "        # Transform images if necessary\n",
        "        X_sample = self.transform_img(X_sample)\n",
        "        y_sample = self.transform_mask(y_sample)\n",
        "        return X_sample, y_sample\n",
        "\n",
        "def create_random_transformation(n):\n",
        "    transformations_img, transformations_mask = [], []\n",
        "    # Identify ranges of possible parameter values\n",
        "    brightness = np.linspace(0, 0.2, 10)\n",
        "    contrast = np.linspace(0, 0.2, 10)\n",
        "    saturation = np.linspace(0, 0.2, 10)\n",
        "    hue = np.linspace(0, 0.2, 10)\n",
        "    hflip = np.array([0, 1])\n",
        "    vflip = np.array([0, 1])\n",
        "    rotate = np.linspace(0, 360, 36)\n",
        "    \n",
        "    for _ in range(n):\n",
        "        # Select specific parameter values for images and GTs\n",
        "        b = np.random.choice(brightness)\n",
        "        c = np.random.choice(contrast)\n",
        "        s = np.random.choice(saturation)\n",
        "        hu = np.random.choice(hue)\n",
        "        h = np.random.choice(hflip)\n",
        "        v = np.random.choice(vflip)\n",
        "        r = np.random.choice(rotate)\n",
        "        # Transform for images\n",
        "        transform_img = transforms.Compose([\n",
        "            transforms.ColorJitter(brightness=b, contrast=c, saturation=s, hue=hu), \n",
        "            transforms.RandomHorizontalFlip(p=h),\n",
        "            transforms.RandomVerticalFlip(p=v),\n",
        "            transforms.RandomRotation(degrees=(r,r)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        transformations_img.append(transform_img)\n",
        "        \n",
        "        # Transform for GTs\n",
        "        transform_mask = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=h),\n",
        "            transforms.RandomVerticalFlip(p=v),\n",
        "            transforms.RandomRotation(degrees=(r,r)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        transformations_mask.append(transform_mask)\n",
        "    \n",
        "    return transformations_img, transformations_mask\n",
        "\n",
        "\n",
        "def create_loaders(img, labels, n_augmented):\n",
        "    transformations_img, transformations_mask = create_random_transformation(n_augmented)\n",
        "    org_train_img, org_val_img, org_train_labels, org_val_labels = train_test_split(img,\n",
        "                                    labels,\n",
        "                                    test_size=train_val_split) \n",
        "    org_train = NumPyDataset(org_train_img, \n",
        "                             org_train_labels, \n",
        "                             transform_img=transforms.ToTensor(), \n",
        "                             transform_mask=transforms.ToTensor()) \n",
        "    augmented_train = [NumPyDataset(org_train_img, \n",
        "                                    org_train_labels, \n",
        "                                    transform_img=trans_img, \n",
        "                                    transform_mask=trans_mask)\\\n",
        "                     for trans_img, trans_mask in zip(transformations_img, transformations_mask)]\n",
        "    augmented_train.append(org_train)\n",
        "    train_dataset = utils.ConcatDataset(augmented_train)\n",
        "    \n",
        "    org_val = NumPyDataset(org_val_img, org_val_labels, transform_img=transforms.ToTensor(), transform_mask=transforms.ToTensor()) \n",
        "    \n",
        "    train_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\n",
        "    validation_loader = utils.DataLoader(org_val, batch_size=batch_size)\n",
        "    return train_loader, validation_loader"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}